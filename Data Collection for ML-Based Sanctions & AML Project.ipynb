{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eacf5f43-ffc0-482c-a2e6-2910ab5deb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests # For simulating API calls\n",
    "from bs4 import BeautifulSoup # For simulating HTML table extraction\n",
    "import datetime\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "090d22f9-438a-487c-8bc0-321424a8998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for Data Generation ---\n",
    "NUM_CUSTOMERS = 12820 # Number of dummy customer records\n",
    "NUM_TRANSACTIONS = 500000 # Number of dummy transaction records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4253a734-95f5-4d58-810b-062a58c0b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for loading common names from Excel\n",
    "COMMON_NAMES_FILE = 'Name_list.xlsx'\n",
    "COMMON_NAMES_SHEET = 'Names' # Assuming names are in a sheet named 'Names'\n",
    "\n",
    "# List of common full names (will be loaded from Excel or use default if file not found)\n",
    "# This list will be populated by the load_common_names_from_excel function\n",
    "COMMON_FULL_NAMES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f97ff620-28e5-4ae0-9435-91d2b12ac303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries and their simulated risk levels\n",
    "# In a real scenario, these would come from external geopolitical risk data providers\n",
    "COUNTRY_RISK_MAP = {\n",
    "    'IRAN': 'HIGH', 'NORTH KOREA': 'HIGH', 'SYRIA': 'HIGH', 'CUBA': 'HIGH', 'VENEZUELA': 'HIGH',\n",
    "    'RUSSIA': 'MEDIUM', 'CHINA': 'MEDIUM', 'INDIA': 'LOW', 'USA': 'LOW', 'UK': 'LOW',\n",
    "    'GERMANY': 'LOW', 'FRANCE': 'LOW', 'BRAZIL': 'MEDIUM', 'SOUTH AFRICA': 'MEDIUM',\n",
    "    'NIGERIA': 'MEDIUM', 'AFGHANISTAN': 'HIGH', 'YEMEN': 'HIGH', 'SOMALIA': 'HIGH',\n",
    "    'LEBANON': 'MEDIUM', 'PAKISTAN': 'MEDIUM'\n",
    "}\n",
    "HIGH_RISK_COUNTRIES = [country for country, risk in COUNTRY_RISK_MAP.items() if risk == 'HIGH']\n",
    "MEDIUM_RISK_COUNTRIES = [country for country, risk in COUNTRY_RISK_MAP.items() if risk == 'MEDIUM']\n",
    "LOW_RISK_COUNTRIES = [country for country, risk in COUNTRY_RISK_MAP.items() if risk == 'LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "503ccb8c-c2af-420c-a1a1-2edd607867fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded common names from 'Name_list.xlsx' sheet 'Names'.\n"
     ]
    }
   ],
   "source": [
    "# --- Helper function to load common names from Excel ---\n",
    "# Added 'sheet_name' parameter back to the function definition\n",
    "def load_common_names_from_excel(filepath, sheet_name):\n",
    "    \"\"\"\n",
    "    Loads a list of full names from an Excel file.\n",
    "    Assumes the names are in a column named 'Sanctioned_name' in the specified sheet.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file, specifying the sheet name\n",
    "        names_df = pd.read_excel(filepath, sheet_name=sheet_name)\n",
    "        # Changed expected column name to 'Sanctioned_name' as per your request\n",
    "        if 'Sanctioned_name' in names_df.columns:\n",
    "            print(f\"Successfully loaded common names from '{filepath}' sheet '{sheet_name}'.\")\n",
    "            return names_df['Sanctioned_name'].astype(str).tolist()\n",
    "        else:\n",
    "            # Corrected error message to use the passed sheet_name\n",
    "            print(f\"Error: 'Sanctioned_name' column not found in '{sheet_name}' of '{filepath}'.\")\n",
    "            return []\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Common names file '{filepath}' not found. Using default hardcoded names.\")\n",
    "        return [\n",
    "            'John Smith', 'Jane Johnson', 'Michael Williams', 'Emily Brown', 'David Jones',\n",
    "            'Sarah Garcia', 'Chris Miller', 'Anna Davis', 'Robert Rodriguez', 'Maria Martinez',\n",
    "            'William Taylor', 'Olivia Wilson', 'James Moore', 'Sophia White', 'Benjamin Green',\n",
    "            'Isabella Hall', 'Lucas King', 'Mia Wright', 'Henry Lopez', 'Charlotte Hill'\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading common names from Excel: {e}\")\n",
    "        return [\n",
    "            'John Smith', 'Jane Johnson', 'Michael Williams', 'Emily Brown', 'David Jones',\n",
    "            'Sarah Garcia', 'Chris Miller', 'Anna Davis', 'Robert Rodriguez', 'Maria Martinez',\n",
    "            'William Taylor', 'Olivia Wilson', 'James Moore', 'Sophia White', 'Benjamin Green',\n",
    "            'Isabella Hall', 'Lucas King', 'Mia Wright', 'Henry Lopez', 'Charlotte Hill'\n",
    "        ]\n",
    "\n",
    "# Load common names at the start\n",
    "# This line is now correct and uses the string variables defined above\n",
    "COMMON_FULL_NAMES = load_common_names_from_excel(COMMON_NAMES_FILE, COMMON_NAMES_SHEET)\n",
    "if not COMMON_FULL_NAMES:\n",
    "    print(\"FATAL: COMMON_FULL_NAMES list is empty after attempting to load from Excel and using default. Exiting.\")\n",
    "    exit() # Exit if no names are available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cbf4eb52-d97b-4d7a-afcd-956408e54284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading Sanctions Data from UK Sanctions List_mean.csv ---\n",
      "Successfully loaded C:/Users/hp952/UK Sanctions List_mean.csv. Shape: (12377, 6)\n",
      "First 5 rows of raw sanctions data:\n",
      "  Sanctioned_ID             Sanctioned_name Sanctioned_Address Sanctioned_DOB  \\\n",
      "0     Cust00001  ZADACHIN ANDREI ANDREEVICH                NaN           1990   \n",
      "1     Cust00002                         1-P        KAFIA KINGI           1994   \n",
      "2     Cust00003                         1-P        KAFIA KINGI           1993   \n",
      "3     Cust00004                         1-P        KAFIA KINGI           1995   \n",
      "4     Cust00005                         1-P        KAFIA KINGI           1992   \n",
      "\n",
      "  Sanctioned_Nationality         Sanctioned_Type  \n",
      "0                 Russia  Primary name variation  \n",
      "1                      0                     AKA  \n",
      "2                      0                     AKA  \n",
      "3                      0                     AKA  \n",
      "4                      0                     AKA  \n",
      "\n",
      "✅ Cleaned Sanctions Data (first 5 rows):\n",
      "  Sanctioned_Id             Sanctioned_Name Sanctioned_Address Sanctioned_Dob  \\\n",
      "0     Cust00001  ZADACHIN ANDREI ANDREEVICH                NAN             90   \n",
      "1     Cust00002                         1-P        KAFIA KINGI             94   \n",
      "2     Cust00003                         1-P        KAFIA KINGI             93   \n",
      "3     Cust00004                         1-P        KAFIA KINGI             95   \n",
      "4     Cust00005                         1-P        KAFIA KINGI             92   \n",
      "\n",
      "  Sanctioned_Nationality         Sanctioned_Type  \n",
      "0                 RUSSIA  PRIMARY NAME VARIATION  \n",
      "1                      0                     AKA  \n",
      "2                      0                     AKA  \n",
      "3                      0                     AKA  \n",
      "4                      0                     AKA  \n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Sanctions Data (Using your provided UK Sanctions List CSV) ---\n",
    "\n",
    "print(\"--- Step 1: Loading Sanctions Data from UK Sanctions List_mean.csv ---\")\n",
    "\n",
    "sanctions_csv_path = 'C:/Users/hp952/UK Sanctions List_mean.csv'\n",
    "\n",
    "try:\n",
    "    # Try reading with a compatible encoding\n",
    "    sanctions_df = pd.read_csv(sanctions_csv_path, header=0, encoding='ISO-8859-1')  # or 'cp1252'\n",
    "    print(f\"Successfully loaded {sanctions_csv_path}. Shape: {sanctions_df.shape}\")\n",
    "    print(\"First 5 rows of raw sanctions data:\")\n",
    "    print(sanctions_df.head())\n",
    "\n",
    "    # Renaming columns (optional: use if original columns differ from expected names)\n",
    "    sanctions_df.columns = sanctions_df.columns.str.strip().str.replace(' ', '_').str.title()\n",
    "\n",
    "    # Clean and standardize key fields\n",
    "    sanctions_df['Sanctioned_Name'] = sanctions_df['Sanctioned_Name'].astype(str).str.upper().str.strip()\n",
    "    sanctions_df['Sanctioned_Address'] = sanctions_df['Sanctioned_Address'].astype(str).str.upper().str.strip()\n",
    "    sanctions_df['Sanctioned_Dob'] = pd.to_datetime(sanctions_df['Sanctioned_Dob'], errors='coerce').dt.strftime('%y')\n",
    "    sanctions_df['Sanctioned_Nationality'] = sanctions_df['Sanctioned_Nationality'].astype(str).str.upper().str.strip()\n",
    "    sanctions_df['Sanctioned_Type'] = sanctions_df['Sanctioned_Type'].astype(str).str.upper().str.strip()\n",
    "    sanctions_df['Sanctioned_Id'] = sanctions_df['Sanctioned_Id'].astype(str)\n",
    "\n",
    "    # Clean: Drop rows where name is missing or unknown\n",
    "    sanctions_df_cleaned = sanctions_df[\n",
    "        (sanctions_df['Sanctioned_Name'] != 'UNKNOWN SANCTIONED NAME') &\n",
    "        (sanctions_df['Sanctioned_Name'].str.strip() != '') &\n",
    "        (sanctions_df['Sanctioned_Name'].str.lower() != 'nan')\n",
    "    ].copy()\n",
    "\n",
    "    # Final selected columns\n",
    "    sanctions_df_cleaned = sanctions_df_cleaned[[\n",
    "        'Sanctioned_Id', 'Sanctioned_Name', 'Sanctioned_Address',\n",
    "        'Sanctioned_Dob', 'Sanctioned_Nationality', 'Sanctioned_Type'\n",
    "    ]]\n",
    "\n",
    "    print(\"\\n✅ Cleaned Sanctions Data (first 5 rows):\")\n",
    "    print(sanctions_df_cleaned.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The file '{sanctions_csv_path}' was not found.\")\n",
    "    sanctions_df_cleaned = pd.DataFrame()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred while processing the sanctions CSV: {e}\")\n",
    "    sanctions_df_cleaned = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "305b54f6-64e5-4691-b2e6-28facb14c937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Simulating Customer Data ---\n",
      "Generated 12820 dummy customer records. Shape: (12820, 8)\n",
      "First 5 rows of dummy customer data:\n",
      "  Customer_Id                 Customer_Name Customer_Address Customer_Dob  \\\n",
      "0   CUST00001           GHARIB FADIL MAHMUD      190 Oak Ave   1959-10-13   \n",
      "1   CUST00002  MANTUROV DENIS VALENTINOVICH      162 Oak Ave   1991-02-13   \n",
      "2   CUST00003                   TRINITI JSC      515 Main St   1955-02-19   \n",
      "3   CUST00004    SAVELYEV OLEG GENRIKHOVICH      191 Oak Ave   1971-12-13   \n",
      "4   CUST00005     TAYMAZOV ARTUR BORISOVICH      611 Oak Ave   1977-08-01   \n",
      "\n",
      "  Customer_Nationality Customer_Country   Customer_Industry Onboarding_Date  \n",
      "0               RUSSIA          SOMALIA  Financial Services      2022-04-05  \n",
      "1         SOUTH AFRICA             CUBA              Retail      2022-01-04  \n",
      "2                INDIA          NIGERIA              Retail      2022-02-27  \n",
      "3                INDIA          GERMANY       Manufacturing      2021-05-28  \n",
      "4              SOMALIA             IRAN       Manufacturing      2022-08-07  \n",
      "Customer data saved to 'customer_data.csv'\n",
      "Customer data saved to 'customer_data.json'\n",
      "\n",
      "Loading customer data from 'customer_data.json' (simulated JSON ingestion):\n",
      "  Customer_Id                 Customer_Name Customer_Address Customer_Dob  \\\n",
      "0   CUST00001           GHARIB FADIL MAHMUD      190 Oak Ave   1959-10-13   \n",
      "1   CUST00002  MANTUROV DENIS VALENTINOVICH      162 Oak Ave   1991-02-13   \n",
      "\n",
      "  Customer_Nationality Customer_Country   Customer_Industry Onboarding_Date  \n",
      "0               RUSSIA          SOMALIA  Financial Services      2022-04-05  \n",
      "1         SOUTH AFRICA             CUBA              Retail      2022-01-04  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Step 2: Simulating Customer Data (CSV and JSON) ---\n",
    "print(\"\\n--- Step 2: Simulating Customer Data ---\")\n",
    "\n",
    "def generate_dummy_customer_data(num_customers):\n",
    "    \"\"\"Generates a DataFrame of dummy customer data.\"\"\"\n",
    "    customers = []\n",
    "    for i in range(1, num_customers + 1):\n",
    "        customer_id = f'CUST{i:05d}'\n",
    "        # Use a single full name from the new list\n",
    "        customer_name = random.choice(COMMON_FULL_NAMES)\n",
    "        customer_address = f\"{random.randint(100, 999)} {random.choice(['Main St', 'Oak Ave', 'Pine Ln'])}\"\n",
    "        customer_dob = (datetime.date(1950, 1, 1) + datetime.timedelta(days=random.randint(0, 365 * 50))).strftime('%Y-%m-%d')\n",
    "        customer_nationality = random.choice(list(COUNTRY_RISK_MAP.keys()))\n",
    "        customer_country = random.choice(list(COUNTRY_RISK_MAP.keys()))\n",
    "        customer_industry = random.choice(['Financial Services', 'Retail', 'Technology', 'Manufacturing', 'Healthcare'])\n",
    "        onboarding_date = (datetime.date(2020, 1, 1) + datetime.timedelta(days=random.randint(0, 365 * 3))).strftime('%Y-%m-%d')\n",
    "\n",
    "        # Introduce some 'risky' customers that might match sanctions list\n",
    "        if i % 10 == 0 and not sanctions_df_cleaned.empty: # Every 10th customer, try to make a fuzzy match\n",
    "            sanctioned_entity = sanctions_df_cleaned.sample(1).iloc[0]\n",
    "            customer_name = sanctioned_entity['Sanctioned_Name'].replace('A', 'a', 1).replace('E', 'e', 1) # Slight variation\n",
    "            customer_address = sanctioned_entity['Sanctioned_Address'].replace('ST', 'Street', 1) # Slight variation\n",
    "            customer_dob = sanctioned_entity['Sanctioned_Dob'] # Exact DOB match\n",
    "            customer_nationality = sanctioned_entity['Sanctioned_Nationality']\n",
    "            customer_country = sanctioned_entity['Sanctioned_Nationality'] # Assume country is same as nationality for simplicity\n",
    "\n",
    "        customers.append({\n",
    "            'Customer_Id': customer_id,\n",
    "            'Customer_Name': customer_name,\n",
    "            'Customer_Address': customer_address,\n",
    "            'Customer_Dob': customer_dob,\n",
    "            'Customer_Nationality': customer_nationality,\n",
    "            'Customer_Country': customer_country,\n",
    "            'Customer_Industry': customer_industry,\n",
    "            'Onboarding_Date': onboarding_date\n",
    "        })\n",
    "    return pd.DataFrame(customers)\n",
    "\n",
    "customer_df = generate_dummy_customer_data(NUM_CUSTOMERS)\n",
    "print(f\"Generated {NUM_CUSTOMERS} dummy customer records. Shape: {customer_df.shape}\")\n",
    "print(\"First 5 rows of dummy customer data:\")\n",
    "print(customer_df.head())\n",
    "\n",
    "# Save as CSV\n",
    "customer_df.to_csv('customer_data.csv', index=False)\n",
    "print(\"Customer data saved to 'customer_data.csv'\")\n",
    "\n",
    "# Save as JSON (example of another format)\n",
    "customer_df.to_json('customer_data.json', orient='records', indent=4)\n",
    "print(\"Customer data saved to 'customer_data.json'\")\n",
    "\n",
    "# --- Loading Customer Data from JSON (Example) ---\n",
    "# This simulates loading from a JSON data provider\n",
    "print(\"\\nLoading customer data from 'customer_data.json' (simulated JSON ingestion):\")\n",
    "customer_df_from_json = pd.read_json('customer_data.json')\n",
    "print(customer_df_from_json.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ad2f2b2-a636-4feb-a6fd-b9886a0a1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 3: Simulating Transaction Data ---\n",
      "Generated 500000 dummy transaction records. Shape: (500000, 8)\n",
      "First 5 rows of dummy transaction data:\n",
      "  Transaction_ID Customer_ID Transaction_Date    Amount Currency  \\\n",
      "0     TXN0000001   CUST01799       2024-04-13  67473.47      GBP   \n",
      "1     TXN0000002   CUST01728       2024-03-13  91786.34      GBP   \n",
      "2     TXN0000003   CUST10895       2024-04-06  41728.63      INR   \n",
      "3     TXN0000004   CUST06337       2024-03-30  38780.99      GBP   \n",
      "4     TXN0000005   CUST10354       2024-01-21  65506.06      EUR   \n",
      "\n",
      "                                   Counterparty_Name Counterparty_Country  \\\n",
      "0  OPERATING ORGANIZATION OF ZAPORIZHZHIA NUCLEAR...               FRANCE   \n",
      "1                        ABDIKADIR ABDIKADIR MOHAMED          AFGHANISTAN   \n",
      "2                                       FREE DONBASS                   UK   \n",
      "3                           B&H WEST COUNTRY SECTION                   UK   \n",
      "4                                   BIN MARWAN BILAL                   UK   \n",
      "\n",
      "  Transaction_Type  \n",
      "0    Wire Transfer  \n",
      "1              ACH  \n",
      "2     Card Payment  \n",
      "3     Card Payment  \n",
      "4     Cash Deposit  \n",
      "Transaction data saved to 'transaction_data.csv'\n",
      "\n",
      "Simulating API call for transactions (e.g., for CUST00001):\n",
      "  Transaction_ID Customer_ID Transaction_Date    Amount Currency  \\\n",
      "0     TXN0001391   CUST00001       2024-05-24   8380.64      GBP   \n",
      "1     TXN0030264   CUST00001       2024-02-18  70189.27      EUR   \n",
      "2     TXN0031109   CUST00001       2024-03-16   8018.11      USD   \n",
      "3     TXN0050213   CUST00001       2024-03-08  35665.43      USD   \n",
      "4     TXN0059272   CUST00001       2024-05-01  87818.14      USD   \n",
      "\n",
      "                                   Counterparty_Name Counterparty_Country  \\\n",
      "0                  AL-BADHALI MUBARAK MISHKHIS SANAD                   UK   \n",
      "1                            CEBALLOS ICHASO REMIGIO               FRANCE   \n",
      "2  JOINT STOCK COMMERCIAL BANK MOSCOW INDUSTRIAL ...                   UK   \n",
      "3                        GURZHIY ANDREY ANATOLYEVICH                  USA   \n",
      "4                                    GHORB-E KARBALA              GERMANY   \n",
      "\n",
      "  Transaction_Type  \n",
      "0  Cash Withdrawal  \n",
      "1  Cash Withdrawal  \n",
      "2              ACH  \n",
      "3     Cash Deposit  \n",
      "4    Wire Transfer  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 3: Simulating Transaction Data (CSV and API) ---\n",
    "print(\"\\n--- Step 3: Simulating Transaction Data ---\")\n",
    "\n",
    "def generate_dummy_transaction_data(num_transactions, customer_ids):\n",
    "    \"\"\"Generates a DataFrame of dummy transaction data.\"\"\"\n",
    "    transactions = []\n",
    "    for i in range(1, num_transactions + 1):\n",
    "        transaction_id = f'TXN{i:07d}'\n",
    "        customer_id = random.choice(customer_ids)\n",
    "        transaction_date = (datetime.date(2024, 1, 1) + datetime.timedelta(days=random.randint(0, 150))).strftime('%Y-%m-%d')\n",
    "        amount = round(random.uniform(100, 100000), 2)\n",
    "        currency = random.choice(['USD', 'EUR', 'GBP', 'INR'])\n",
    "        transaction_type = random.choice(['Wire Transfer', 'ACH', 'Card Payment', 'Cash Deposit', 'Cash Withdrawal'])\n",
    "        \n",
    "        # Introduce some 'risky' transactions\n",
    "        counterparty_name = random.choice(COMMON_FULL_NAMES) # Use the new full names list\n",
    "        counterparty_country = random.choice(LOW_RISK_COUNTRIES) # Default to low risk\n",
    "\n",
    "        if random.random() < 0.1: # 10% chance for a high-risk country transaction\n",
    "            counterparty_country = random.choice(HIGH_RISK_COUNTRIES)\n",
    "            if random.random() < 0.3 and not sanctions_df_cleaned.empty: # 30% chance for a counterparty name similar to sanctioned\n",
    "                sanctioned_entity = sanctions_df_cleaned.sample(1).iloc[0]\n",
    "                counterparty_name = sanctioned_entity['Sanctioned_Name'].replace('O', 'o', 1) # Slight variation\n",
    "\n",
    "        transactions.append({\n",
    "            'Transaction_ID': transaction_id,\n",
    "            'Customer_ID': customer_id,\n",
    "            'Transaction_Date': transaction_date,\n",
    "            'Amount': amount,\n",
    "            'Currency': currency,\n",
    "            'Counterparty_Name': counterparty_name,\n",
    "            'Counterparty_Country': counterparty_country,\n",
    "            'Transaction_Type': transaction_type\n",
    "        })\n",
    "    return pd.DataFrame(transactions)\n",
    "\n",
    "transaction_df = generate_dummy_transaction_data(NUM_TRANSACTIONS, customer_df['Customer_Id'].tolist())\n",
    "print(f\"Generated {NUM_TRANSACTIONS} dummy transaction records. Shape: {transaction_df.shape}\")\n",
    "print(\"First 5 rows of dummy transaction data:\")\n",
    "print(transaction_df.head())\n",
    "\n",
    "# Save as CSV\n",
    "transaction_df.to_csv('transaction_data.csv', index=False)\n",
    "print(\"Transaction data saved to 'transaction_data.csv'\")\n",
    "\n",
    "# --- Simulating API Data Provider for Transaction Data ---\n",
    "# In a real scenario, you'd make an actual HTTP request to an API endpoint.\n",
    "# Here, we'll simulate an API response by converting our DataFrame to JSON.\n",
    "\n",
    "def get_transactions_from_api_mock(customer_id=None, limit=100):\n",
    "    \"\"\"\n",
    "    Simulates fetching transaction data from an API.\n",
    "    In a real API, you'd use requests.get(api_url, params={'customer_id': customer_id, 'limit': limit})\n",
    "    \"\"\"\n",
    "    if customer_id:\n",
    "        filtered_txns = transaction_df[transaction_df['Customer_ID'] == customer_id].head(limit)\n",
    "    else:\n",
    "        filtered_txns = transaction_df.head(limit)\n",
    "    \n",
    "    # Simulate API response structure (e.g., JSON)\n",
    "    return {'status': 'success', 'data': filtered_txns.to_dict(orient='records')}\n",
    "\n",
    "print(\"\\nSimulating API call for transactions (e.g., for CUST00001):\")\n",
    "api_response = get_transactions_from_api_mock(customer_id='CUST00001', limit=5)\n",
    "if api_response['status'] == 'success':\n",
    "    api_transactions_df = pd.DataFrame(api_response['data'])\n",
    "    print(api_transactions_df)\n",
    "else:\n",
    "    print(\"API call failed (simulated).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "84604775-8652-4276-8720-6a1350efab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Simulating External Data Sources (Geopolitical Risk, Adverse Media) ---\n",
      "\n",
      "Simulated Geopolitical Risk Data (from COUNTRY_RISK_MAP):\n",
      "  IRAN: HIGH\n",
      "  NORTH KOREA: HIGH\n",
      "  SYRIA: HIGH\n",
      "  CUBA: HIGH\n",
      "  VENEZUELA: HIGH\n",
      "  RUSSIA: MEDIUM\n",
      "  CHINA: MEDIUM\n",
      "  INDIA: LOW\n",
      "  USA: LOW\n",
      "  UK: LOW\n",
      "  GERMANY: LOW\n",
      "  FRANCE: LOW\n",
      "  BRAZIL: MEDIUM\n",
      "  SOUTH AFRICA: MEDIUM\n",
      "  NIGERIA: MEDIUM\n",
      "  AFGHANISTAN: HIGH\n",
      "  YEMEN: HIGH\n",
      "  SOMALIA: HIGH\n",
      "  LEBANON: MEDIUM\n",
      "  PAKISTAN: MEDIUM\n",
      "\n",
      "Simulating Adverse Media Screening for 'JOHN DOE':\n",
      "{'hit': True, 'severity': 'HIGH', 'keywords': ['fraud', 'sanctions evasion']}\n",
      "\n",
      "Simulating Adverse Media Screening for 'Robert Johnson':\n",
      "{'hit': False}\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Simulating External Data Sources ---\n",
    "print(\"\\n--- Step 4: Simulating External Data Sources (Geopolitical Risk, Adverse Media) ---\")\n",
    "\n",
    "# Geopolitical Risk Data (Simple Dictionary Lookup)\n",
    "# This would typically come from a structured file or API from a risk data provider.\n",
    "# For simplicity, we'll use our COUNTRY_RISK_MAP directly.\n",
    "print(\"\\nSimulated Geopolitical Risk Data (from COUNTRY_RISK_MAP):\")\n",
    "for country, risk in COUNTRY_RISK_MAP.items():\n",
    "    print(f\"  {country}: {risk}\")\n",
    "\n",
    "# Adverse Media Screening (AMS) Data (Simulated API/CSV)\n",
    "# In reality, this would involve searching news articles for a name and getting a sentiment/risk score.\n",
    "def get_adverse_media_hit_mock(name):\n",
    "    \"\"\"Simulates an adverse media screening API call.\"\"\"\n",
    "    mock_media_data = {\n",
    "        'JOHN DOE': {'hit': True, 'severity': 'HIGH', 'keywords': ['fraud', 'sanctions evasion']},\n",
    "        'JANE SMITH': {'hit': True, 'severity': 'MEDIUM', 'keywords': ['money laundering investigation']},\n",
    "        'ALIBABA': {'hit': False}, # No hit for this one\n",
    "        'VLADIMIR PUTIN': {'hit': True, 'severity': 'CRITICAL', 'keywords': ['sanctioned leader', 'corruption']},\n",
    "        'KIM JONG-UN': {'hit': True, 'severity': 'CRITICAL', 'keywords': ['nuclear program', 'human rights violations']},\n",
    "    }\n",
    "    # Normalize name for lookup\n",
    "    clean_name = name.upper().strip()\n",
    "    return mock_media_data.get(clean_name, {'hit': False})\n",
    "\n",
    "print(\"\\nSimulating Adverse Media Screening for 'JOHN DOE':\")\n",
    "print(get_adverse_media_hit_mock('JOHN DOE'))\n",
    "print(\"\\nSimulating Adverse Media Screening for 'Robert Johnson':\")\n",
    "print(get_adverse_media_hit_mock('Robert Johnson'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "860f0f6c-87f0-4b37-a617-900745122cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 5: HTML Table Extraction (Demonstration Only) ---\n",
      "Error during HTML parsing: 3 columns passed, passed data had 4 columns\n",
      "\n",
      "--- Summary of Loaded DataFrames ---\n",
      "Sanctions Data (cleaned): 12377 rows\n",
      "Customer Data (simulated): 12820 rows\n",
      "Transaction Data (simulated): 500000 rows\n",
      "\n",
      "Data collection simulation complete. You now have cleaned sanctions data and generated dummy customer and transaction data ready for the next steps.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 5: HTML Table Extraction (Less common for sensitive data, but for demonstration) ---\n",
    "print(\"\\n--- Step 5: HTML Table Extraction (Demonstration Only) ---\")\n",
    "# This is typically used for publicly available, less sensitive data like stock tables.\n",
    "# Not recommended for core sanctions or AML data due to lack of reliability and legal issues.\n",
    "\n",
    "# Example: Simulate a simple HTML table\n",
    "html_content = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "  <h1>Public Data Table</h1>\n",
    "  <table id=\"myTable\">\n",
    "    <thead>\n",
    "      <tr><th>Name</th><th>City</th><th>Status</th></tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr><td>Alice</td><td>New York</td><td>Active</td></tr>\n",
    "      <tr><td>Bob</td><td>London</td><td>Inactive</td></tr>\n",
    "      <tr><td><td>Charlie</td><td>Paris</td><td>Active</td></tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Using BeautifulSoup to parse HTML and extract table\n",
    "try:\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'myTable'})\n",
    "    \n",
    "    if table:\n",
    "        headers = [th.text for th in table.find('thead').find_all('th')]\n",
    "        rows = []\n",
    "        for tr in table.find('tbody').find_all('tr'):\n",
    "            rows.append([td.text for td in tr.find_all('td')])\n",
    "        \n",
    "        html_df = pd.DataFrame(rows, columns=headers)\n",
    "        print(\"\\nData extracted from simulated HTML table:\")\n",
    "        print(html_df)\n",
    "    else:\n",
    "        print(\"No table found with id 'myTable' in simulated HTML.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during HTML parsing: {e}\")\n",
    "\n",
    "\n",
    "# --- Summary of Loaded DataFrames ---\n",
    "print(\"\\n--- Summary of Loaded DataFrames ---\")\n",
    "print(f\"Sanctions Data (cleaned): {sanctions_df_cleaned.shape[0]} rows\")\n",
    "print(f\"Customer Data (simulated): {customer_df.shape[0]} rows\")\n",
    "print(f\"Transaction Data (simulated): {transaction_df.shape[0]} rows\")\n",
    "\n",
    "print(\"\\nData collection simulation complete. You now have cleaned sanctions data and generated dummy customer and transaction data ready for the next steps.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
