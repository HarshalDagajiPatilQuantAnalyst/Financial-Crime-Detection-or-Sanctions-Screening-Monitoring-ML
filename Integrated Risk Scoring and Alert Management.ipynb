{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b60bc8-e337-48a3-80c3-1083dc0190d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Integrated Risk Scoring and Alert Management ---\n",
      "Successfully loaded UK Sanctions List_mean.csv with 'latin1' encoding. Shape: (12376, 6)\n",
      "FATAL: No suitable name column found in sanctions CSV. Using dummy data for sanctions.\n",
      "An unexpected error occurred during sanctions data loading/cleaning: No name column found. Generating dummy sanctions data.\n",
      "Generated fallback sanctions data due to error.\n",
      "Successfully loaded customer data from customer_data.csv. Shape: (12820, 8)\n",
      "Standardized customer column names: {'Customer_Id': 'Customer_ID', 'Customer_Name': 'Customer_Name', 'Customer_Address': 'Customer_Address', 'Customer_Dob': 'Customer_DOB', 'Customer_Nationality': 'Customer_Nationality', 'Customer_Country': 'Customer_Country', 'Customer_Industry': 'Customer_Industry', 'Onboarding_Date': 'Onboarding_Date'}\n",
      "Customer DataFrame columns after standardization: ['Customer_ID', 'Customer_Name', 'Customer_Address', 'Customer_DOB', 'Customer_Nationality', 'Customer_Country', 'Customer_Industry', 'Onboarding_Date']\n",
      "Loaded Sanctions Screening Results. Shape: (1215, 5)\n",
      "Loaded AML Transaction Monitoring Results. Shape: (100000, 6)\n",
      "\n",
      "--- Calculating Integrated Risk Scores ---\n",
      "\n",
      "Integrated Risk Score Calculation Complete. Sample of results:\n",
      "     Customer_ID                Customer_Name  Customer_Country_Risk_Score  \\\n",
      "9933   CUST09934                          TTP                         10.0   \n",
      "9553   CUST09554        AL-AJURI ABU MUHAMMAD                         10.0   \n",
      "2758   CUST02759                  LLC SPINNER                         10.0   \n",
      "2711   CUST02712       OBEYD MAHER REBHI NAMR                         10.0   \n",
      "6733   CUST06734  GAIDUKEVICH OLEG SERGEEVICH                         10.0   \n",
      "\n",
      "      Max_Sanction_Match_Probability  Num_AML_Alerts  Min_Anomaly_Score  \\\n",
      "9933                             0.0             4.0          -0.097363   \n",
      "9553                             0.0             6.0          -0.093469   \n",
      "2758                             0.0             7.0          -0.091253   \n",
      "2711                             0.0             8.0          -0.090085   \n",
      "6733                             0.0            10.0          -0.089738   \n",
      "\n",
      "      Integrated_Risk_Score Overall_Risk_Level  \n",
      "9933              45.154922             MEDIUM  \n",
      "9553              45.009271             MEDIUM  \n",
      "2758              44.926373             MEDIUM  \n",
      "2711              44.882699             MEDIUM  \n",
      "6733              44.869709             MEDIUM  \n",
      "\n",
      "--- Generating Consolidated Alerts Summary (Threshold: 50) ---\n",
      "No high-risk alerts generated based on the integrated risk score threshold.\n",
      "\n",
      "Final integrated AML alerts saved to 'final_aml_integrated_alerts.csv'\n",
      "\n",
      "--- Integrated Risk Scoring and Alert Management Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import joblib # For loading models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configuration and Global Variables (consistent with previous steps) ---\n",
    "NUM_CUSTOMERS = 500\n",
    "NUM_TRANSACTIONS = 100000\n",
    "\n",
    "# Country Risk Map (simulated external data)\n",
    "COUNTRY_RISK_MAP = {\n",
    "    'IRAN': 'HIGH', 'NORTH KOREA': 'HIGH', 'SYRIA': 'HIGH', 'CUBA': 'HIGH', 'VENEZUULA': 'HIGH',\n",
    "    'RUSSIA': 'MEDIUM', 'CHINA': 'MEDIUM', 'INDIA': 'LOW', 'USA': 'LOW', 'UK': 'LOW',\n",
    "    'GERMANY': 'LOW', 'FRANCE': 'LOW', 'BRAZIL': 'MEDIUM', 'SOUTH AFRICA': 'MEDIUM',\n",
    "    'NIGERIA': 'MEDIUM', 'AFGHANISTAN': 'HIGH', 'YEMEN': 'HIGH', 'SOMALIA': 'HIGH',\n",
    "    'LEBANON': 'MEDIUM', 'PAKISTAN': 'MEDIUM'\n",
    "}\n",
    "HIGH_RISK_COUNTRIES = [country for country, risk in COUNTRY_RISK_MAP.items() if risk == 'HIGH']\n",
    "LOW_RISK_COUNTRIES = [country for country, risk in COUNTRY_RISK_MAP.items() if risk == 'LOW']\n",
    "\n",
    "# --- Helper Functions for Data Loading and Generation (copied for self-containment) ---\n",
    "\n",
    "def load_common_names_from_excel(filepath, sheet_name):\n",
    "    \"\"\"\n",
    "    Loads a list of full names from an Excel file.\n",
    "    Assumes the names are in a column named 'Sanctioned_name' in the specified sheet.\n",
    "    Provides a fallback to a hardcoded list if the file or column is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        names_df = pd.read_excel(filepath, sheet_name=sheet_name)\n",
    "        if 'Sanctioned_name' in names_df.columns:\n",
    "            return names_df['Sanctioned_name'].astype(str).tolist()\n",
    "        else:\n",
    "            return _get_default_common_names()\n",
    "    except FileNotFoundError:\n",
    "        return _get_default_common_names()\n",
    "    except Exception as e:\n",
    "        return _get_default_common_names()\n",
    "\n",
    "def _get_default_common_names():\n",
    "    \"\"\"Provides a hardcoded list of common names as a fallback.\"\"\"\n",
    "    return [\n",
    "        'John Smith', 'Jane Johnson', 'Michael Williams', 'Emily Brown', 'David Jones',\n",
    "        'Sarah Garcia', 'Chris Miller', 'Anna Davis', 'Robert Rodriguez', 'Maria Martinez',\n",
    "        'William Taylor', 'Olivia Wilson', 'James Moore', 'Sophia White', 'Benjamin Green',\n",
    "        'Isabella Hall', 'Lucas King', 'Mia Wright', 'Henry Lopez', 'Charlotte Hill'\n",
    "    ]\n",
    "\n",
    "def load_or_generate_initial_data(sanctions_csv_path='UK Sanctions List_mean.csv',\n",
    "                                   customer_data_path='customer_data.csv',\n",
    "                                   num_customers=None):\n",
    "    \"\"\"\n",
    "    Loads cleaned sanctions and customer data. If files are not found,\n",
    "    it generates minimal dummy data for demonstration.\n",
    "    \"\"\"\n",
    "    if num_customers is None:\n",
    "        num_customers = NUM_CUSTOMERS\n",
    "\n",
    "    global COMMON_FULL_NAMES\n",
    "    COMMON_FULL_NAMES = load_common_names_from_excel('Name_list.xlsx', 'Names')\n",
    "\n",
    "    if not COMMON_FULL_NAMES:\n",
    "        print(\"FATAL: COMMON_FULL_NAMES list is empty. Cannot proceed with data generation.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    sanctions_df_cleaned = pd.DataFrame()\n",
    "    customer_df = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        raw_sanctions_df = pd.read_csv(sanctions_csv_path, encoding='latin1', header=1)\n",
    "        print(f\"Successfully loaded {sanctions_csv_path} with 'latin1' encoding. Shape: {raw_sanctions_df.shape}\")\n",
    "\n",
    "        name_col = 'Name 6'\n",
    "        address_col = 'Address 6'\n",
    "        dob_col = 'DOB 6'\n",
    "        nationality_col = 'Nationality 6'\n",
    "        type_col = 'Type'\n",
    "        id_col = 'ID'\n",
    "\n",
    "        actual_name_col = name_col if name_col in raw_sanctions_df.columns else ('Name' if 'Name' in raw_sanctions_df.columns else None)\n",
    "        actual_address_col = address_col if address_col in raw_sanctions_df.columns else ('Address' if 'Address' in raw_sanctions_df.columns else None)\n",
    "        actual_dob_col = dob_col if dob_col in raw_sanctions_df.columns else ('DOB' if 'DOB' in raw_sanctions_df.columns else None)\n",
    "        actual_nationality_col = nationality_col if nationality_col in raw_sanctions_df.columns else ('Nationality' if 'Nationality' in raw_sanctions_df.columns else None)\n",
    "        actual_type_col = type_col if type_col in raw_sanctions_df.columns else ('Type' if 'Type' in raw_sanctions_df.columns else None)\n",
    "        actual_id_col = id_col if id_col in raw_sanctions_df.columns else ('ID' if 'ID' in raw_sanctions_df.columns else None)\n",
    "\n",
    "        if not actual_name_col:\n",
    "            print(f\"FATAL: No suitable name column found in sanctions CSV. Using dummy data for sanctions.\")\n",
    "            raise ValueError(\"No name column found\")\n",
    "\n",
    "        sanctions_df_cleaned = raw_sanctions_df.copy()\n",
    "        sanctions_df_cleaned['Sanctioned_Name'] = sanctions_df_cleaned[actual_name_col].astype(str).str.upper().str.strip()\n",
    "        \n",
    "        sanctions_df_cleaned['Sanctioned_Address'] = sanctions_df_cleaned[actual_address_col].astype(str).str.upper().str.strip() if actual_address_col and actual_address_col in sanctions_df_cleaned.columns else np.nan\n",
    "        sanctions_df_cleaned['Sanctioned_DOB'] = pd.to_datetime(sanctions_df_cleaned[actual_dob_col], errors='coerce').dt.strftime('%Y-%m-%d') if actual_dob_col and actual_dob_col in sanctions_df_cleaned.columns else np.nan\n",
    "        sanctions_df_cleaned['Sanctioned_Nationality'] = sanctions_df_cleaned[actual_nationality_col].astype(str).str.upper().str.strip() if actual_nationality_col and actual_nationality_col in sanctions_df_cleaned.columns else np.nan\n",
    "        sanctions_df_cleaned['Sanction_Type'] = sanctions_df_cleaned[actual_type_col].astype(str).str.upper().str.strip() if actual_type_col and actual_type_col in sanctions_df_cleaned.columns else np.nan\n",
    "        sanctions_df_cleaned['Sanctioned_ID'] = sanctions_df_cleaned[actual_id_col].astype(str) if actual_id_col and actual_id_col in sanctions_df_cleaned.columns else [f'S{i:04d}' for i in range(len(sanctions_df_cleaned))]\n",
    "\n",
    "        sanctions_df_cleaned = sanctions_df_cleaned[[\n",
    "            'Sanctioned_ID', 'Sanctioned_Name', 'Sanctioned_Address',\n",
    "            'Sanctioned_DOB', 'Sanctioned_Nationality', 'Sanction_Type'\n",
    "        ]].copy()\n",
    "        sanctions_df_cleaned = sanctions_df_cleaned[\n",
    "            (sanctions_df_cleaned['Sanctioned_Name'] != 'UNKNOWN SANCTIONED NAME') &\n",
    "            (sanctions_df_cleaned['Sanctioned_Name'] != 'NAN') &\n",
    "            (sanctions_df_cleaned['Sanctioned_Name'].str.strip() != '')\n",
    "        ].reset_index(drop=True)\n",
    "        print(\"Cleaned Sanctions Data (first 3 rows):\")\n",
    "        print(sanctions_df_cleaned.head(3))\n",
    "        sanctions_df_cleaned.to_csv('sanctions_list_cleaned.csv', index=False)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Sanctions file '{sanctions_csv_path}' not found. Generating minimal dummy sanctions data.\")\n",
    "        sanctions_df_cleaned = pd.DataFrame({\n",
    "            'Sanctioned_ID': [f'S{i:04d}' for i in range(1, 101)],\n",
    "            'Sanctioned_Name': [f'SANCTIONED PERSON {i}' for i in range(1, 101)],\n",
    "            'Sanctioned_Address': [f'{i*10} MAIN ST, HIGH RISK COUNTRY' for i in range(1, 101)],\n",
    "            'Sanctioned_DOB': [f'{1950 + i}-01-01' for i in range(100)],\n",
    "            'Sanctioned_Nationality': random.choices(HIGH_RISK_COUNTRIES, k=100),\n",
    "            'Sanction_Type': random.choices(['INDIVIDUAL', 'ENTITY'], k=100)\n",
    "        })\n",
    "        print(\"Generated fallback sanctions data.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during sanctions data loading/cleaning: {e}. Generating dummy sanctions data.\")\n",
    "        sanctions_df_cleaned = pd.DataFrame({\n",
    "            'Sanctioned_ID': [f'S{i:04d}' for i in range(1, 101)],\n",
    "            'Sanctioned_Name': [f'SANCTIONED PERSON {i}' for i in range(1, 101)],\n",
    "            'Sanctioned_Address': [f'{i*10} MAIN ST, HIGH RISK COUNTRY' for i in range(1, 101)],\n",
    "            'Sanctioned_DOB': [f'{1950 + i}-01-01' for i in range(100)],\n",
    "            'Sanctioned_Nationality': random.choices(HIGH_RISK_COUNTRIES, k=100),\n",
    "            'Sanction_Type': random.choices(['INDIVIDUAL', 'ENTITY'], k=100)\n",
    "        })\n",
    "        print(\"Generated fallback sanctions data due to error.\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        customer_df = pd.read_csv(customer_data_path)\n",
    "        print(f\"Successfully loaded customer data from {customer_data_path}. Shape: {customer_df.shape}\")\n",
    "\n",
    "        current_cols_lower = {col.lower(): col for col in customer_df.columns}\n",
    "        \n",
    "        expected_customer_cols_mapping = {\n",
    "            'customer_id': 'Customer_ID',\n",
    "            'customer_name': 'Customer_Name',\n",
    "            'customer_address': 'Customer_Address',\n",
    "            'customer_dob': 'Customer_DOB',\n",
    "            'customer_nationality': 'Customer_Nationality',\n",
    "            'customer_country': 'Customer_Country',\n",
    "            'customer_industry': 'Customer_Industry',\n",
    "            'onboarding_date': 'Onboarding_Date'\n",
    "        }\n",
    "        \n",
    "        rename_dict = {}\n",
    "        for old_col_lower, new_col_proper in expected_customer_cols_mapping.items():\n",
    "            if old_col_lower in current_cols_lower:\n",
    "                rename_dict[current_cols_lower[old_col_lower]] = new_col_proper\n",
    "            elif new_col_proper not in customer_df.columns:\n",
    "                print(f\"Warning: Customer column '{new_col_proper}' not found in loaded data. Creating as NaN.\")\n",
    "                customer_df[new_col_proper] = np.nan\n",
    "\n",
    "        if rename_dict:\n",
    "            customer_df.rename(columns=rename_dict, inplace=True)\n",
    "            print(f\"Standardized customer column names: {rename_dict}\")\n",
    "            \n",
    "        print(f\"Customer DataFrame columns after standardization: {customer_df.columns.tolist()}\")\n",
    "\n",
    "        required_customer_cols = ['Customer_ID', 'Customer_Name', 'Customer_Address', 'Customer_DOB', 'Customer_Nationality', 'Customer_Country']\n",
    "        if not all(col in customer_df.columns for col in required_customer_cols):\n",
    "            missing_cols = [col for col in required_customer_cols if col not in customer_df.columns]\n",
    "            print(f\"FATAL: Missing required customer columns after loading/standardization: {missing_cols}. Cannot proceed.\")\n",
    "            customer_df = pd.DataFrame() \n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Customer data file '{customer_data_path}' not found. Generating dummy customer data.\")\n",
    "        customers = []\n",
    "        for i in range(1, num_customers + 1):\n",
    "            customer_id = f'CUST{i:05d}'\n",
    "            customer_name = random.choice(COMMON_FULL_NAMES)\n",
    "            customer_address = f\"{random.randint(100, 999)} {random.choice(['Main St', 'Oak Ave', 'Pine Ln'])}\"\n",
    "            customer_dob = (datetime.date(1950, 1, 1) + datetime.timedelta(days=random.randint(0, 365 * 50))).strftime('%Y-%m-%d')\n",
    "            customer_nationality = random.choice(list(COUNTRY_RISK_MAP.keys()))\n",
    "            customer_country = random.choice(list(COUNTRY_RISK_MAP.keys()))\n",
    "            customer_industry = random.choice(['Financial Services', 'Retail', 'Technology', 'Manufacturing', 'Healthcare'])\n",
    "            onboarding_date = (datetime.date(2020, 1, 1) + datetime.timedelta(days=random.randint(0, 365 * 3))).strftime('%Y-%m-%d')\n",
    "\n",
    "            if i % 10 == 0 and not sanctions_df_cleaned.empty:\n",
    "                sanctioned_entity = sanctions_df_cleaned.sample(1).iloc[0]\n",
    "                customer_name = sanctioned_entity['Sanctioned_Name'].replace('A', 'a', 1).replace('E', 'e', 1)\n",
    "                customer_address = sanctioned_entity['Sanctioned_Address'].replace('ST', 'Street', 1)\n",
    "                customer_dob = sanctioned_entity['Sanctioned_DOB']\n",
    "                customer_nationality = sanctioned_entity['Sanctioned_Nationality']\n",
    "                customer_country = sanctioned_entity['Sanctioned_Nationality']\n",
    "\n",
    "            customers.append({\n",
    "                'Customer_ID': customer_id,\n",
    "                'Customer_Name': customer_name,\n",
    "                'Customer_Address': customer_address,\n",
    "                'Customer_DOB': customer_dob,\n",
    "                'Customer_Nationality': customer_nationality,\n",
    "                'Customer_Country': customer_country,\n",
    "                'Customer_Industry': customer_industry,\n",
    "                'Onboarding_Date': onboarding_date\n",
    "            })\n",
    "        customer_df = pd.DataFrame(customers)\n",
    "        customer_df.to_csv(customer_data_path, index=False)\n",
    "        print(\"Generated dummy customer data.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during customer data loading/generation: {e}. Generating dummy customer data.\")\n",
    "        customers = []\n",
    "        for i in range(1, num_customers + 1):\n",
    "            customer_id = f'CUST{i:05d}'\n",
    "            customer_name = random.choice(COMMON_FULL_NAMES)\n",
    "            customer_address = f\"{random.randint(100, 999)} {random.choice(['Main St', 'Oak Ave', 'Pine Ln'])}\"\n",
    "            customer_dob = (datetime.date(1950, 1, 1) + datetime.timedelta(days=random.randint(0, 365 * 50))).strftime('%Y-%m-%d')\n",
    "            customer_nationality = random.choice(list(COUNTRY_RISK_MAP.keys()))\n",
    "            customer_country = random.choice(list(COUNTRY_RISK_MAP.keys()))\n",
    "            customer_industry = random.choice(['Financial Services', 'Retail', 'Technology', 'Manufacturing', 'Healthcare'])\n",
    "            onboarding_date = (datetime.date(2020, 1, 1) + datetime.timedelta(days=random.randint(0, 365 * 3))).strftime('%Y-%m-%d')\n",
    "            customers.append({\n",
    "                'Customer_ID': customer_id, 'Customer_Name': customer_name, 'Customer_Address': customer_address,\n",
    "                'Customer_DOB': customer_dob, 'Customer_Nationality': customer_nationality, 'Customer_Country': customer_country,\n",
    "                'Customer_Industry': customer_industry, 'Onboarding_Date': onboarding_date\n",
    "            })\n",
    "        customer_df = pd.DataFrame(customers)\n",
    "        print(\"Generated fallback customer data due to error.\")\n",
    "\n",
    "    return sanctions_df_cleaned, customer_df\n",
    "\n",
    "# --- New Functions for Integrated Risk Scoring and Alert Management (Step 5) ---\n",
    "\n",
    "def calculate_integrated_risk(customer_df, sanctions_results_df, aml_results_df):\n",
    "    \"\"\"\n",
    "    Combines results from sanctions screening and AML transaction monitoring\n",
    "    to calculate an integrated risk score for each customer.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Calculating Integrated Risk Scores ---\")\n",
    "\n",
    "    # Ensure customer_df has a 'Customer_Country' column for risk mapping\n",
    "    if 'Customer_Country' not in customer_df.columns:\n",
    "        print(\"Warning: 'Customer_Country' not found in customer_df. Adding as NaN and mapping to 0 risk.\")\n",
    "        customer_df['Customer_Country'] = np.nan\n",
    "    \n",
    "    # Map customer country risk (from previous step's logic)\n",
    "    customer_df['Customer_Country_Risk_Score'] = customer_df['Customer_Country'].astype(str).str.upper().map(\n",
    "        {k: (10 if v == 'HIGH' else 5 if v == 'MEDIUM' else 1) for k, v in COUNTRY_RISK_MAP.items()}\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Merge sanctions results\n",
    "    # Use 'how=left' to keep all customers, even if they had no sanctions alerts\n",
    "    customer_risk_df = pd.merge(\n",
    "        customer_df[['Customer_ID', 'Customer_Name', 'Customer_Country_Risk_Score']],\n",
    "        sanctions_results_df[['Customer_ID', 'Max_Sanction_Match_Probability', 'Sanction_Alert_Flag']],\n",
    "        on='Customer_ID',\n",
    "        how='left'\n",
    "    )\n",
    "    # Fill NaNs for customers with no sanctions alerts\n",
    "    customer_risk_df['Max_Sanction_Match_Probability'] = customer_risk_df['Max_Sanction_Match_Probability'].fillna(0)\n",
    "    customer_risk_df['Sanction_Alert_Flag'] = customer_risk_df['Sanction_Alert_Flag'].fillna('OK')\n",
    "\n",
    "    # Merge AML results (aggregate AML alerts per customer)\n",
    "    # For AML, we're interested in the *highest* anomaly score (lowest decision_function) for a customer\n",
    "    # and the count of alerts.\n",
    "    aml_customer_summary = aml_results_df[aml_results_df['AML_Alert_Flag'] == 'ALERT'].groupby('Customer_ID').agg(\n",
    "        Num_AML_Alerts=('Transaction_ID', 'count'),\n",
    "        Min_Anomaly_Score=('Anomaly_Score', 'min') # Lower score means higher anomaly\n",
    "    ).reset_index()\n",
    "\n",
    "    # Merge AML summary into the main customer risk DataFrame\n",
    "    customer_risk_df = pd.merge(\n",
    "        customer_risk_df,\n",
    "        aml_customer_summary,\n",
    "        on='Customer_ID',\n",
    "        how='left'\n",
    "    )\n",
    "    # Fill NaNs for customers with no AML alerts\n",
    "    customer_risk_df['Num_AML_Alerts'] = customer_risk_df['Num_AML_Alerts'].fillna(0)\n",
    "    customer_risk_df['Min_Anomaly_Score'] = customer_risk_df['Min_Anomaly_Score'].fillna(1) # Max Isolation Forest score is 1\n",
    "\n",
    "    # --- Calculate Integrated Risk Score ---\n",
    "    # This is a simplified weighted sum. Weights can be tuned based on business rules and risk appetite.\n",
    "    # Higher score = higher risk.\n",
    "    # Sanctions probability is already 0-100.\n",
    "    # AML anomaly score is typically negative for anomalies, positive for normal.\n",
    "    # We'll normalize AML anomaly score to contribute positively to risk.\n",
    "    \n",
    "    # Normalize AML anomaly score: (1 - score) makes lower scores (more anomalous) higher risk.\n",
    "    # We'll clip it to ensure it's within a reasonable range, e.g., 0 to 1.\n",
    "    # Max possible anomaly score is around 0.5 for IsolationForest, min is -0.5 to -1.\n",
    "    # Let's map it to a 0-100 scale where 100 is most anomalous.\n",
    "    # A simple way is to take (max_score - actual_score) / (max_score - min_score)\n",
    "    # For Isolation Forest, decision_function usually ranges from approx -0.5 to 0.5.\n",
    "    # Let's map -0.5 to 100, 0.5 to 0.\n",
    "    \n",
    "    # Example mapping:\n",
    "    # If Min_Anomaly_Score is -0.5 (very anomalous), mapped_aml_risk = 100\n",
    "    # If Min_Anomaly_Score is 0.5 (very normal), mapped_aml_risk = 0\n",
    "    \n",
    "    # Simple linear mapping for illustration:\n",
    "    min_if_score = customer_risk_df['Min_Anomaly_Score'].min()\n",
    "    max_if_score = customer_risk_df['Min_Anomaly_Score'].max()\n",
    "    \n",
    "    # Avoid division by zero if all scores are the same\n",
    "    if max_if_score - min_if_score == 0:\n",
    "        customer_risk_df['Mapped_AML_Risk'] = 0 # No variation, no risk from this component\n",
    "    else:\n",
    "        customer_risk_df['Mapped_AML_Risk'] = (max_if_score - customer_risk_df['Min_Anomaly_Score']) / (max_if_score - min_if_score) * 100\n",
    "    \n",
    "    # Ensure it's not negative and cap at 100\n",
    "    customer_risk_df['Mapped_AML_Risk'] = customer_risk_df['Mapped_AML_Risk'].clip(lower=0, upper=100)\n",
    "    \n",
    "    # Define weights for each component\n",
    "    W_CUSTOMER_RISK = 0.3 # Weight for inherent customer risk (e.g., country)\n",
    "    W_SANCTIONS_ALERT = 0.4 # Weight for sanctions match probability\n",
    "    W_AML_ALERTS = 0.3 # Weight for transaction anomaly score/count\n",
    "\n",
    "    customer_risk_df['Integrated_Risk_Score'] = (\n",
    "        customer_risk_df['Customer_Country_Risk_Score'] * W_CUSTOMER_RISK +\n",
    "        customer_risk_df['Max_Sanction_Match_Probability'] * W_SANCTIONS_ALERT +\n",
    "        customer_risk_df['Mapped_AML_Risk'] * W_AML_ALERTS\n",
    "    )\n",
    "\n",
    "    # Normalize Integrated_Risk_Score to a 0-100 scale (optional, but good for interpretability)\n",
    "    max_possible_integrated_score = (10 * W_CUSTOMER_RISK + 100 * W_SANCTIONS_ALERT + 100 * W_AML_ALERTS)\n",
    "    customer_risk_df['Integrated_Risk_Score'] = (customer_risk_df['Integrated_Risk_Score'] / max_possible_integrated_score) * 100\n",
    "    \n",
    "    # Classify overall risk level\n",
    "    customer_risk_df['Overall_Risk_Level'] = pd.cut(\n",
    "        customer_risk_df['Integrated_Risk_Score'],\n",
    "        bins=[0, 30, 60, 100],\n",
    "        labels=['LOW', 'MEDIUM', 'HIGH'],\n",
    "        right=False,\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    print(\"\\nIntegrated Risk Score Calculation Complete. Sample of results:\")\n",
    "    print(customer_risk_df[['Customer_ID', 'Customer_Name', 'Customer_Country_Risk_Score',\n",
    "                            'Max_Sanction_Match_Probability', 'Num_AML_Alerts', 'Min_Anomaly_Score',\n",
    "                            'Integrated_Risk_Score', 'Overall_Risk_Level']].sort_values(by='Integrated_Risk_Score', ascending=False).head())\n",
    "    \n",
    "    return customer_risk_df\n",
    "\n",
    "def generate_alerts_summary(integrated_risk_df, alert_threshold_score=50):\n",
    "    \"\"\"\n",
    "    Generates a summary of alerts based on the integrated risk score.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Generating Consolidated Alerts Summary (Threshold: {alert_threshold_score}) ---\")\n",
    "\n",
    "    alerts_df = integrated_risk_df[integrated_risk_df['Integrated_Risk_Score'] >= alert_threshold_score].copy()\n",
    "    \n",
    "    if alerts_df.empty:\n",
    "        print(\"No high-risk alerts generated based on the integrated risk score threshold.\")\n",
    "        return pd.DataFrame(columns=['Customer_ID', 'Customer_Name', 'Integrated_Risk_Score', 'Overall_Risk_Level',\n",
    "                                     'Sanction_Alert_Flag', 'Num_AML_Alerts', 'Alert_Reason'])\n",
    "\n",
    "    # Add a simple 'Alert_Reason' column\n",
    "    alerts_df['Alert_Reason'] = ''\n",
    "    alerts_df.loc[alerts_df['Sanction_Alert_Flag'] == 'ALERT', 'Alert_Reason'] += 'Sanctions Match; '\n",
    "    alerts_df.loc[alerts_df['Num_AML_Alerts'] > 0, 'Alert_Reason'] += 'Transaction Anomaly; '\n",
    "    alerts_df.loc[alerts_df['Customer_Country_Risk_Score'] >= 5, 'Alert_Reason'] += 'High Country Risk; '\n",
    "    alerts_df['Alert_Reason'] = alerts_df['Alert_Reason'].str.strip('; ')\n",
    "    alerts_df.loc[alerts_df['Alert_Reason'] == '', 'Alert_Reason'] = 'High Integrated Risk' # Fallback\n",
    "\n",
    "    # Sort alerts by risk score\n",
    "    alerts_df = alerts_df.sort_values(by='Integrated_Risk_Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Total High-Risk Alerts: {len(alerts_df)}\")\n",
    "    print(\"\\nTop 10 Consolidated Alerts:\")\n",
    "    print(alerts_df[['Customer_ID', 'Customer_Name', 'Integrated_Risk_Score', 'Overall_Risk_Level', 'Alert_Reason']].head(10))\n",
    "\n",
    "    # Visualize alert distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='Overall_Risk_Level', data=alerts_df, order=['LOW', 'MEDIUM', 'HIGH'], palette='viridis')\n",
    "    plt.title('Distribution of Overall Risk Levels for Alerts')\n",
    "    plt.xlabel('Risk Level')\n",
    "    plt.ylabel('Number of Customers')\n",
    "    plt.show()\n",
    "\n",
    "    return alerts_df[['Customer_ID', 'Customer_Name', 'Integrated_Risk_Score', 'Overall_Risk_Level', 'Sanction_Alert_Flag', 'Num_AML_Alerts', 'Alert_Reason']]\n",
    "\n",
    "\n",
    "# --- Main Execution Flow for Integrated Risk Scoring and Alert Management ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Starting Integrated Risk Scoring and Alert Management ---\")\n",
    "\n",
    "    # 1. Load Initial Customer Data\n",
    "    # We need the full customer_df for customer country risk and merging\n",
    "    sanctions_dummy_df, customer_df = load_or_generate_initial_data()\n",
    "    if customer_df.empty:\n",
    "        print(\"FATAL: Customer data could not be loaded or generated. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. Load Results from Previous ML Steps\n",
    "    try:\n",
    "        sanctions_results_df = pd.read_csv('final_sanctions_screening_results.csv')\n",
    "        print(f\"Loaded Sanctions Screening Results. Shape: {sanctions_results_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: 'final_sanctions_screening_results.csv' not found. Creating dummy sanctions results.\")\n",
    "        # Create a dummy sanctions results DataFrame if the file is missing\n",
    "        sanctions_results_df = customer_df[['Customer_ID', 'Customer_Name']].copy()\n",
    "        sanctions_results_df['Max_Sanction_Match_Probability'] = 0\n",
    "        sanctions_results_df['Sanction_Alert_Flag'] = 'OK'\n",
    "        # Inject a few dummy alerts for demonstration\n",
    "        if not sanctions_results_df.empty:\n",
    "            num_dummy_alerts = min(10, len(sanctions_results_df) // 10)\n",
    "            dummy_alert_indices = random.sample(range(len(sanctions_results_df)), num_dummy_alerts)\n",
    "            sanctions_results_df.loc[dummy_alert_indices, 'Max_Sanction_Match_Probability'] = np.random.uniform(0.6, 0.9, num_dummy_alerts) * 100\n",
    "            sanctions_results_df.loc[dummy_alert_indices, 'Sanction_Alert_Flag'] = 'ALERT'\n",
    "\n",
    "\n",
    "    try:\n",
    "        aml_results_df = pd.read_csv('final_aml_screening_results.csv')\n",
    "        print(f\"Loaded AML Transaction Monitoring Results. Shape: {aml_results_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: 'final_aml_screening_results.csv' not found. Creating dummy AML results.\")\n",
    "        # Create a dummy AML results DataFrame if the file is missing\n",
    "        aml_results_df = pd.DataFrame(columns=['Transaction_ID', 'Customer_ID', 'Amount_USD', 'Anomaly_Score', 'AML_Alert_Flag', 'Is_Suspicious_Label'])\n",
    "        # Generate some dummy AML alerts if customer_df is available\n",
    "        if not customer_df.empty:\n",
    "            dummy_transactions = []\n",
    "            customer_ids = customer_df['Customer_ID'].tolist()\n",
    "            num_dummy_aml_trans = min(100, NUM_TRANSACTIONS // 100) # Generate a small number of dummy transactions\n",
    "            for i in range(num_dummy_aml_trans):\n",
    "                cust_id = random.choice(customer_ids)\n",
    "                is_alert = 1 if random.random() < 0.2 else 0 # 20% chance of alert\n",
    "                anomaly_score = random.uniform(-0.5, 0.0) if is_alert else random.uniform(0.0, 0.5)\n",
    "                dummy_transactions.append({\n",
    "                    'Transaction_ID': f'DUMMY_TRANS{i:04d}',\n",
    "                    'Customer_ID': cust_id,\n",
    "                    'Amount_USD': random.uniform(100, 100000),\n",
    "                    'Anomaly_Score': anomaly_score,\n",
    "                    'AML_Alert_Flag': 'ALERT' if is_alert else 'OK',\n",
    "                    'Is_Suspicious_Label': is_alert # For consistency\n",
    "                })\n",
    "            aml_results_df = pd.DataFrame(dummy_transactions)\n",
    "\n",
    "\n",
    "    # 3. Calculate Integrated Risk Scores\n",
    "    integrated_risk_df = calculate_integrated_risk(customer_df.copy(), sanctions_results_df.copy(), aml_results_df.copy())\n",
    "\n",
    "    # 4. Generate Consolidated Alerts Summary\n",
    "    final_alerts_summary_df = generate_alerts_summary(integrated_risk_df.copy(), alert_threshold_score=50)\n",
    "\n",
    "    # Save the final alerts summary\n",
    "    final_alerts_summary_df.to_csv('final_aml_integrated_alerts.csv', index=False)\n",
    "    print(\"\\nFinal integrated AML alerts saved to 'final_aml_integrated_alerts.csv'\")\n",
    "\n",
    "    print(\"\\n--- Integrated Risk Scoring and Alert Management Complete ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
